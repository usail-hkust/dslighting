# web_ui/backend/app/services/agent_dispatcher.py

"""
Agent Dispatcher - ä¸­å¤®è°ƒåº¦å™¨ï¼ˆæ”¯æŒæ‰€æœ‰agentäº’ç›¸è°ƒç”¨ï¼‰

è¿™æ˜¯agentä¹‹é—´é€šä¿¡çš„æ ¸å¿ƒç»„ä»¶ï¼Œè´Ÿè´£ï¼š
1. è·¯ç”±agentè°ƒç”¨è¯·æ±‚
2. ç®¡ç†agentä¹‹é—´çš„ä¾èµ–å…³ç³»
3. æä¾›ç»Ÿä¸€çš„è°ƒç”¨æ¥å£
4. å¤„ç†è°ƒç”¨é“¾å’Œä¸Šä¸‹æ–‡ä¼ é€’
"""

import logging
import json
from pathlib import Path
from typing import Dict, Any, Optional, List, Union
from .agent_registry import (
    AgentType, get_agent_capabilities, get_capability_info,
    can_agent_call, get_agent_description
)
from .llm_factory import get_llm
from .chat_logic import (
    _run_active_exploration,
    _read_eda_context,
    _verify_prepared_data
)
from ..models.llm_formats import CodeResponse, ChatResponse

logger = logging.getLogger(__name__)


class AgentDispatcher:
    """
    Agentä¸­å¤®è°ƒåº¦å™¨

    æ‰€æœ‰agentä¹‹é—´çš„è°ƒç”¨éƒ½é€šè¿‡è¿™ä¸ªdispatcherè¿›è¡Œã€‚
    å®ƒè´Ÿè´£ï¼š
    - éªŒè¯è°ƒç”¨æƒé™
    - è·¯ç”±åˆ°æ­£ç¡®çš„agentå®ç°
    - ä¼ é€’ä¸Šä¸‹æ–‡ä¿¡æ¯
    - å¤„ç†è°ƒç”¨é“¾
    - æ£€æµ‹å’Œé˜²æ­¢å¾ªç¯è°ƒç”¨
    """

    # é…ç½®å¸¸é‡
    MAX_CALL_DEPTH = 10  # æœ€å¤§è°ƒç”¨æ·±åº¦
    MAX_REPEATED_AGENTS = 3  # åŒä¸€agentåœ¨è°ƒç”¨é“¾ä¸­æœ€å¤šå‡ºç°æ¬¡æ•°

    def __init__(
        self,
        sandbox,
        sandbox_dir: Path,
        base_context: str,
        caller_agent: AgentType = AgentType.DATA_EXPLORER,  # é»˜è®¤è°ƒç”¨è€…
        call_chain: Optional[List[AgentType]] = None  # æ”¯æŒä¼ å…¥å·²æœ‰è°ƒç”¨é“¾
    ):
        self.sandbox = sandbox
        self.sandbox_dir = sandbox_dir
        self.base_context = base_context
        self.caller_agent = caller_agent

        # è°ƒç”¨é“¾è¿½è¸ªå’Œå¾ªç¯æ£€æµ‹
        if call_chain is None:
            self.call_chain: List[AgentType] = [caller_agent]
        else:
            self.call_chain = call_chain.copy()

        # è°ƒç”¨å†å²è®°å½•ï¼ˆç”¨äºæ£€æµ‹æ¨¡å¼ï¼‰
        self.call_history: List[Dict[str, Any]] = []

    async def call(
        self,
        target_agent: AgentType,
        capability: str,
        **kwargs
    ) -> Dict[str, Any]:
        """
        é€šç”¨çš„agentè°ƒç”¨æ–¹æ³•ï¼ˆå¸¦å¾ªç¯æ£€æµ‹ï¼‰

        Args:
            target_agent: è¦è°ƒç”¨çš„ç›®æ ‡agent
            capability: è¦ä½¿ç”¨çš„èƒ½åŠ›åç§°
            **kwargs: èƒ½åŠ›ç‰¹å®šçš„å‚æ•°

        Returns:
            DictåŒ…å«è°ƒç”¨ç»“æœ
        """
        # 1. æ£€æŸ¥è°ƒç”¨æƒé™
        if not can_agent_call(self.caller_agent, target_agent):
            logger.warning(f"âš ï¸ {self.caller_agent.value} ä¸å…è®¸è°ƒç”¨ {target_agent.value}")
            return {
                "success": False,
                "error": f"Permission denied: {self.caller_agent.value} cannot call {target_agent.value}"
            }

        # 2. æ£€æŸ¥è°ƒç”¨æ·±åº¦
        if len(self.call_chain) >= self.MAX_CALL_DEPTH:
            logger.error(f"ğŸš« è¾¾åˆ°æœ€å¤§è°ƒç”¨æ·±åº¦ ({self.MAX_CALL_DEPTH})")
            logger.error(f"   è°ƒç”¨é“¾: {' â†’ '.join([a.value for a in self.call_chain])}")
            return {
                "success": False,
                "error": f"Maximum call depth ({self.MAX_CALL_DEPTH}) exceeded. Possible infinite loop detected."
            }

        # 3. æ£€æµ‹å¾ªç¯æ¨¡å¼
        loop_detection = self._detect_loop_pattern(target_agent)
        if loop_detection["has_loop"]:
            logger.error(f"ğŸš« æ£€æµ‹åˆ°å¾ªç¯è°ƒç”¨æ¨¡å¼: {loop_detection['pattern']}")
            logger.error(f"   è°ƒç”¨é“¾: {' â†’ '.join([a.value for a in self.call_chain])}")
            return {
                "success": False,
                "error": f"Loop detected: {loop_detection['pattern']}. Breaking the loop to prevent infinite recursion."
            }

        # 4. æ£€æŸ¥åŒä¸€agenté‡å¤è°ƒç”¨æ¬¡æ•°
        agent_count = sum(1 for a in self.call_chain if a == target_agent)
        if agent_count >= self.MAX_REPEATED_AGENTS:
            logger.error(f"ğŸš« Agent {target_agent.value} åœ¨è°ƒç”¨é“¾ä¸­å‡ºç° {agent_count} æ¬¡ï¼ˆæœ€å¤š {self.MAX_REPEATED_AGENTS} æ¬¡ï¼‰")
            chain_str = ' â†’ '.join([a.value for a in self.call_chain])
            logger.error(f"   è°ƒç”¨é“¾: {chain_str}")
            return {
                "success": False,
                "error": f"Agent {target_agent.value} called {agent_count} times (max {self.MAX_REPEATED_AGENTS}). Possible loop detected."
            }

        # 5. è®°å½•åˆ°è°ƒç”¨é“¾
        self.call_chain.append(target_agent)
        chain_str = ' â†’ '.join([a.value for a in self.call_chain])
        logger.info(f"ğŸ”— Agentè°ƒç”¨é“¾ (æ·±åº¦={len(self.call_chain)}): {chain_str}")

        # 6. è®°å½•è°ƒç”¨å†å²
        self.call_history.append({
            "caller": self.caller_agent.value,
            "target": target_agent.value,
            "capability": capability,
            "depth": len(self.call_chain)
        })

        # 7. è·¯ç”±åˆ°å…·ä½“çš„agentå®ç°
        try:
            result = await self._route_to_agent(target_agent, capability, **kwargs)
            result["success"] = True
            logger.info(f"âœ… {target_agent.value}.{capability}() æ‰§è¡ŒæˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ {target_agent.value}.{capability}() æ‰§è¡Œå¤±è´¥: {e}")
            result = {
                "success": False,
                "error": str(e)
            }

        # 8. æ¢å¤è°ƒç”¨é“¾
        self.call_chain.pop()

        return result

    def _detect_loop_pattern(self, target_agent: AgentType) -> Dict[str, Any]:
        """
        æ£€æµ‹å¾ªç¯è°ƒç”¨æ¨¡å¼

        æ£€æµ‹ç­–ç•¥ï¼š
        1. ç®€å•å¾ªç¯: A â†’ B â†’ A
        2. é‡å¤æ¨¡å¼: A â†’ B â†’ C â†’ A â†’ B â†’ C
        3. é•¿å¾ªç¯: A â†’ B â†’ C â†’ D â†’ E â†’ A

        Returns:
            {
                "has_loop": bool,
                "pattern": str (å¦‚æœæ£€æµ‹åˆ°å¾ªç¯)
            }
        """
        # æ£€æŸ¥ç®€å•å¾ªç¯ï¼šç›®æ ‡agentå·²ç»åœ¨è°ƒç”¨é“¾ä¸­
        if target_agent in self.call_chain:
            # æ‰¾åˆ°ç›®æ ‡agentåœ¨è°ƒç”¨é“¾ä¸­çš„ä½ç½®
            first_index = self.call_chain.index(target_agent)
            loop_sequence = self.call_chain[first_index:] + [target_agent]

            # æ£€æŸ¥æ˜¯å¦æ˜¯ç«‹å³å¾ªç¯ï¼ˆA â†’ B â†’ Aï¼‰
            if len(loop_sequence) == 2:
                return {
                    "has_loop": True,
                    "pattern": f"Immediate loop: {' â†’ '.join([a.value for a in loop_sequence])}"
                }

            # æ£€æŸ¥æ˜¯å¦æ˜¯çŸ­å¾ªç¯ï¼ˆA â†’ B â†’ C â†’ Aï¼‰
            if len(loop_sequence) <= 4:
                return {
                    "has_loop": True,
                    "pattern": f"Short loop: {' â†’ '.join([a.value for a in loop_sequence])}"
                }

            # é•¿å¾ªç¯è­¦å‘Š
            return {
                "has_loop": True,
                "pattern": f"Long loop detected: {' â†’ '.join([a.value for a in loop_sequence])}"
            }

        # æ£€æŸ¥é‡å¤æ¨¡å¼ï¼ˆA â†’ B â†’ A â†’ Bï¼‰
        if len(self.call_chain) >= 4:
            # æ£€æŸ¥æœ€å4ä¸ªè°ƒç”¨æ˜¯å¦æ˜¯äº¤æ›¿æ¨¡å¼
            recent = self.call_chain[-4:]
            if len(recent) == 4:
                if recent[0] == recent[2] and recent[1] == target_agent:
                    return {
                        "has_loop": True,
                        "pattern": f"Alternating pattern: {recent[0].value} â†” {recent[1].value}"
                    }

        # æ£€æŸ¥é‡å¤çš„ä¸‰å…ƒç»„æ¨¡å¼ï¼ˆA â†’ B â†’ C â†’ A â†’ B â†’ Cï¼‰
        if len(self.call_chain) >= 6:
            recent = self.call_chain[-6:]
            pattern1 = recent[:3]
            pattern2 = recent[3:] + [target_agent]

            if pattern1 == pattern2:
                return {
                    "has_loop": True,
                    "pattern": f"Repeating pattern: {' â†’ '.join([a.value for a in pattern1])}"
                }

        # æ²¡æœ‰æ£€æµ‹åˆ°å¾ªç¯
        return {"has_loop": False, "pattern": ""}

    def get_call_chain_info(self) -> Dict[str, Any]:
        """
        è·å–è°ƒç”¨é“¾ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰

        Returns:
            {
                "current_chain": List[str],
                "depth": int,
                "agent_counts": Dict[str, int],
                "call_history": List[Dict]
            }
        """
        agent_counts = {}
        for agent in self.call_chain:
            agent_counts[agent.value] = agent_counts.get(agent.value, 0) + 1

        return {
            "current_chain": [a.value for a in self.call_chain],
            "depth": len(self.call_chain),
            "agent_counts": agent_counts,
            "call_history": self.call_history[-10:]  # æœ€è¿‘10æ¬¡è°ƒç”¨
        }

    async def _route_to_agent(
        self,
        target_agent: AgentType,
        capability: str,
        **kwargs
    ) -> Dict[str, Any]:
        """è·¯ç”±åˆ°å…·ä½“çš„agentå®ç°"""

        # ========== DataExplorer Agent ==========
        if target_agent == AgentType.DATA_EXPLORER:
            return await self._execute_data_explorer(capability, **kwargs)

        # ========== Debugger Agent ==========
        elif target_agent == AgentType.DEBUGGER:
            return await self._execute_debugger(capability, **kwargs)

        # ========== DataPrep Agent ==========
        elif target_agent == AgentType.DATA_PREP:
            return await self._execute_data_prep(capability, **kwargs)

        # ========== Analyst Agent ==========
        elif target_agent == AgentType.ANALYST:
            return await self._execute_analyst(capability, **kwargs)

        # ========== Reporter Agent ==========
        elif target_agent == AgentType.REPORTER:
            return await self._execute_reporter(capability, **kwargs)

        else:
            raise ValueError(f"Unknown agent type: {target_agent}")

    # ==================== DataExplorer Agent å®ç° ====================

    async def _execute_data_explorer(self, capability: str, **kwargs) -> Dict[str, Any]:
        """æ‰§è¡ŒDataExplorerçš„èƒ½åŠ›"""

        if capability == "analyze_schema":
            # åˆ†ææ•°æ®schema
            error_msg = kwargs.get("error_msg", "")
            file_path = kwargs.get("file_path", "")

            # ä½¿ç”¨å·²æœ‰çš„æ¢ç´¢é€»è¾‘
            loading_guide = await _run_active_exploration(
                self.sandbox,
                error_msg or "Schema analysis request",
                self.base_context,
                kwargs.get("chat_summary", "")
            )

            return {
                "schema_info": self._parse_loading_guide(loading_guide),
                "loading_guide": loading_guide,
                "file_structure": self.get_file_tree_context()
            }

        elif capability == "discover_files":
            # å‘ç°æ–‡ä»¶
            pattern = kwargs.get("pattern", "*")
            files = self._discover_files(pattern)
            file_types = self._classify_files(files)

            return {
                "files": files,
                "file_types": file_types
            }

        elif capability == "detect_encoding":
            # æ£€æµ‹ç¼–ç 
            file_path = kwargs.get("file_path")
            if not file_path:
                raise ValueError("file_path is required for encoding detection")

            encoding = self._detect_file_encoding(file_path)
            return {
                "encoding": encoding,
                "confidence": 0.9
            }

        else:
            raise ValueError(f"Unknown DataExplorer capability: {capability}")

    # ==================== Debugger Agent å®ç° ====================

    async def _execute_debugger(self, capability: str, **kwargs) -> Dict[str, Any]:
        """æ‰§è¡ŒDebuggerçš„èƒ½åŠ›"""

        if capability == "fix_code_error":
            # ä¿®å¤ä»£ç é”™è¯¯
            code = kwargs.get("code")
            error_msg = kwargs.get("error_msg")
            context = kwargs.get("context", "")

            # ä½¿ç”¨LLMä¿®å¤ä»£ç 
            llm = await get_llm()
            fix_prompt = self._create_fix_prompt(code, error_msg, context)

            try:
                res_model = await llm.call_with_json(fix_prompt, output_model=CodeResponse)
                fixed_code = res_model.code.strip()

                return {
                    "fixed_code": fixed_code,
                    "explanation": res_model.thought
                }
            except Exception as e:
                logger.error(f"Debugger failed: {e}")
                raise

        elif capability == "review_code":
            # ä»£ç å®¡æŸ¥
            code = kwargs.get("code")
            llm = await get_llm()
            review_prompt = f"""Please review the following code:

```python
{code}
```

Provide feedback on:
1. Correctness
2. Performance
3. Best practices
4. Potential improvements

Respond in JSON with 'thought' and 'response' fields."""

            try:
                res_model = await llm.call_with_json(review_prompt, output_model=ChatResponse)
                return {
                    "review_result": res_model.response,
                    "suggestions": res_model.thought.split("\n") if res_model.thought else []
                }
            except Exception as e:
                logger.error(f"Code review failed: {e}")
                raise

        elif capability == "optimize_performance":
            # æ€§èƒ½ä¼˜åŒ–
            code = kwargs.get("code")
            llm = await get_llm()
            optimize_prompt = f"""Optimize the following code for better performance:

```python
{code}
```

Identify performance bottlenecks and provide an optimized version.
Respond in JSON with 'thought' and 'code' fields."""

            try:
                res_model = await llm.call_with_json(optimize_prompt, output_model=CodeResponse)
                return {
                    "optimized_code": res_model.code.strip(),
                    "improvements": res_model.thought.split("\n") if res_model.thought else []
                }
            except Exception as e:
                logger.error(f"Performance optimization failed: {e}")
                raise

        else:
            raise ValueError(f"Unknown Debugger capability: {capability}")

    # ==================== DataPrep Agent å®ç° ====================

    async def _execute_data_prep(self, capability: str, **kwargs) -> Dict[str, Any]:
        """æ‰§è¡ŒDataPrepçš„èƒ½åŠ›"""

        if capability == "check_prepared_data":
            # æ£€æŸ¥æ•°æ®å‡†å¤‡çŠ¶æ€
            error = _verify_prepared_data(self.sandbox_dir)
            is_prepared = (error is None)

            prepared_files = []
            if is_prepared:
                prep_dir = self.sandbox_dir / "prepared_data"
                prep_dir_new = self.sandbox_dir / "prepared"

                if prep_dir.exists():
                    prepared_files.extend([str(f) for f in prep_dir.glob("**/*") if f.is_file()])
                if prep_dir_new.exists():
                    prepared_files.extend([str(f) for f in prep_dir_new.glob("**/*") if f.is_file()])

            # è¯»å–manifest
            manifest = {}
            manifest_file = self.sandbox_dir / "manifest.json"
            if manifest_file.exists():
                try:
                    manifest = json.loads(manifest_file.read_text())
                except:
                    pass

            return {
                "is_prepared": is_prepared,
                "prepared_files": prepared_files,
                "manifest": manifest,
                "error": error
            }

        elif capability == "clean_data":
            # æ•°æ®æ¸…æ´—
            source_files = kwargs.get("source_files", [])
            # è¿”å›éœ€è¦æ‰§è¡Œçš„æ¸…æ´—ä»£ç ï¼ˆç”±è°ƒç”¨è€…æ‰§è¡Œï¼‰
            return {
                "cleaned_files": [],
                "cleaning_report": "Data cleaning not yet implemented. Use manual code."
            }

        elif capability == "transform_data":
            # æ•°æ®è½¬æ¢
            return {
                "transformed_files": [],
                "transform_report": "Data transformation not yet implemented. Use manual code."
            }

        elif capability == "split_data":
            # æ•°æ®åˆ†å‰²
            return {
                "train_file": "",
                "test_file": "",
                "answer_file": "",
                "split_report": "Data splitting not yet implemented. Use manual code."
            }

        else:
            raise ValueError(f"Unknown DataPrep capability: {capability}")

    # ==================== Analyst Agent å®ç° ====================

    async def _execute_analyst(self, capability: str, **kwargs) -> Dict[str, Any]:
        """æ‰§è¡ŒAnalystçš„èƒ½åŠ›"""

        if capability == "generate_statistics":
            # ç”Ÿæˆç»Ÿè®¡ï¼ˆéœ€è¦æ‰§è¡Œä»£ç ï¼‰
            data_source = kwargs.get("data_source", "")
            code = f"""import pandas as pd
import numpy as np

# Load data
df = pd.read_csv('{data_source}')

# Generate statistics
print("Shape:", df.shape)
print("\\nColumns:", df.columns.tolist())
print("\\nData Types:\\n", df.dtypes)
print("\\nBasic Statistics:\\n", df.describe())
print("\\nMissing Values:\\n", df.isnull().sum())
print("\\nUnique Values:\\n", df.nunique())
"""

            result = self.sandbox.run_script(code)

            return {
                "statistics": {
                    "stdout": result.stdout,
                    "stderr": result.stderr
                },
                "summary_text": result.stdout,
                "success": result.success
            }

        elif capability == "create_visualization":
            # åˆ›å»ºå¯è§†åŒ–
            data_source = kwargs.get("data_source", "")
            viz_type = kwargs.get("viz_type", "scatter")

            code = f"""import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv('{data_source}')

# Create visualization
if '{viz_type}' == 'scatter':
    df.plot.scatter(x=df.columns[0], y=df.columns[1])
elif '{viz_type}' == 'hist':
    df[df.columns[0]].hist()
else:
    df.plot()

plt.tight_layout()
plt.savefig('analyst_viz.png', dpi=100)
print("Visualization saved to analyst_viz.png")
"""

            result = self.sandbox.run_script(code)

            return {
                "image_paths": ["analyst_viz.png"] if result.success else [],
                "insights": [result.stdout] if result.success else [],
                "success": result.success
            }

        elif capability == "analyze_correlations":
            # ç›¸å…³æ€§åˆ†æ
            data_source = kwargs.get("data_source", "")

            code = f"""import pandas as pd

df = pd.read_csv('{data_source}')

# Select only numeric columns
numeric_df = df.select_dtypes(include=[np.number])

# Calculate correlation
corr = numeric_df.corr()
print("Correlation Matrix:\\n", corr)

# Key correlations
print("\\nKey Correlations:")
for col in corr.columns:
    top_corr = corr[col].abs().sort_values(ascending=False).head(3)
    print(f"\\n{{col}}: {{top_corr.to_dict()}}")
"""

            result = self.sandbox.run_script(code)

            return {
                "correlation_matrix": result.stdout,
                "key_correlations": [],
                "success": result.success
            }

        elif capability == "compare_datasets":
            # æ¯”è¾ƒæ•°æ®é›†
            datasets = kwargs.get("datasets", [])

            if len(datasets) < 2:
                return {"comparison_report": "Need at least 2 datasets to compare", "differences": []}

            # ç”Ÿæˆæ¯”è¾ƒä»£ç 
            code = f"""import pandas as pd
import sys

df1 = pd.read_csv('{datasets[0]}')
df2 = pd.read_csv('{datasets[1]}')

print("Dataset 1 shape:", df1.shape)
print("Dataset 2 shape:", df2.shape)

print("\\nColumns in both:", set(df1.columns) & set(df2.columns))
print("Columns only in df1:", set(df1.columns) - set(df2.columns))
print("Columns only in df2:", set(df2.columns) - set(df1.columns))

# Compare shapes if columns match
if set(df1.columns) == set(df2.columns):
    print("\\nSame columns, comparing sizes...")
    print(f"df1 size: {{len(df1)}}")
    print(f"df2 size: {{len(df2)}}")
"""

            result = self.sandbox.run_script(code)

            return {
                "comparison_report": result.stdout,
                "differences": result.stdout.split("\n"),
                "success": result.success
            }

        else:
            raise ValueError(f"Unknown Analyst capability: {capability}")

    # ==================== Reporter Agent å®ç° ====================

    async def _execute_reporter(self, capability: str, **kwargs) -> Dict[str, Any]:
        """æ‰§è¡ŒReporterçš„èƒ½åŠ›"""

        if capability == "summarize_analysis":
            # æ€»ç»“åˆ†æç»“æœ
            analysis_results = kwargs.get("analysis_results", {})
            focus = kwargs.get("focus", "")

            llm = await get_llm()
            summary_prompt = f"""Please summarize the following analysis results:

{json.dumps(analysis_results, indent=2, ensure_ascii=False)}

Focus: {focus if focus else "Provide a comprehensive summary"}

Respond in JSON with 'thought' and 'response' fields."""

            try:
                res_model = await llm.call_with_json(summary_prompt, output_model=ChatResponse)
                return {
                    "summary": res_model.response,
                    "key_findings": res_model.thought.split("\n") if res_model.thought else []
                }
            except Exception as e:
                logger.error(f"Summary failed: {e}")
                raise

        elif capability == "generate_report":
            # ç”ŸæˆæŠ¥å‘Š
            content = kwargs.get("content", {})
            format_type = kwargs.get("format", "markdown")

            report_content = json.dumps(content, indent=2, ensure_ascii=False)

            if format_type == "markdown":
                # è½¬æ¢ä¸ºmarkdownæ ¼å¼
                report_content = f"# Analysis Report\n\n{report_content}"

            return {
                "report_path": "report.txt",
                "report_content": report_content
            }

        elif capability == "format_insights":
            # æ ¼å¼åŒ–æ´å¯Ÿ
            insights = kwargs.get("insights", [])
            format_style = kwargs.get("format", "bullet")

            if format_style == "bullet":
                formatted = "\n".join([f"â€¢ {insight}" for insight in insights])
            else:
                formatted = "\n".join(insights)

            return {
                "formatted_text": formatted,
                "bullet_points": insights
            }

        else:
            raise ValueError(f"Unknown Reporter capability: {capability}")

    # ==================== è¾…åŠ©æ–¹æ³• ====================

    def get_file_tree_context(self) -> str:
        """è·å–æ–‡ä»¶æ ‘ç»“æ„"""
        try:
            import os
            result = ["## Current Workspace File Structure\n"]

            for root, dirs, files in os.walk(self.sandbox_dir):
                dirs[:] = [d for d in dirs if not d.startswith('.')]
                level = root.replace(str(self.sandbox_dir), '').count(os.sep)
                indent = ' ' * 2 * level
                result.append(f'{indent}{os.path.basename(root)}/')

                subindent = ' ' * 2 * (level + 1)
                for file in sorted(files):
                    if not file.startswith('.'):
                        result.append(f'{subindent}{file}')

            return '\n'.join(result)
        except Exception as e:
            logger.error(f"Failed to get file tree: {e}")
            return "Unable to retrieve file structure"

    def get_data_schema_summary(self) -> str:
        """è·å–æ•°æ®schemaæ‘˜è¦"""
        try:
            import pandas as pd
            result = ["\n## Available Data Files and Schema\n"]

            # æ£€æŸ¥preparedå’Œrawæ•°æ®
            dirs_to_check = [
                self.sandbox_dir / "prepared" / "public",
                self.sandbox_dir / "prepared" / "private",
                self.sandbox_dir / "raw"
            ]

            for dir_path in dirs_to_check:
                if dir_path.exists():
                    for csv_file in dir_path.glob("*.csv"):
                        rel_path = csv_file.relative_to(self.sandbox_dir)
                        result.append(f"\n### {rel_path}")

                        try:
                            df = pd.read_csv(csv_file, nrows=1)
                            result.append(f"**Columns**: {', '.join(df.columns.tolist())}")
                            result.append(f"**Shape**: (rows, {len(df.columns)} columns)")
                            result.append(f"**Dtypes**:\n{df.dtypes.to_string()}")
                        except Exception as e:
                            result.append(f"**Error**: {e}")

            return '\n'.join(result)
        except Exception as e:
            logger.error(f"Failed to get schema summary: {e}")
            return f"Unable to retrieve schema: {e}"

    def _discover_files(self, pattern: str = "*") -> List[str]:
        """å‘ç°æ–‡ä»¶"""
        import os
        files = []
        for root, dirs, filenames in os.walk(self.sandbox_dir):
            for filename in filenames:
                if filename.endswith(pattern) or pattern == "*":
                    files.append(str(Path(root) / filename))
        return files

    def _classify_files(self, files: List[str]) -> Dict[str, int]:
        """åˆ†ç±»æ–‡ä»¶"""
        from collections import Counter
        extensions = [Path(f).suffix.lower() for f in files]
        return dict(Counter(extensions))

    def _detect_file_encoding(self, file_path: str) -> str:
        """æ£€æµ‹æ–‡ä»¶ç¼–ç """
        try:
            # ç®€å•çš„ç¼–ç æ£€æµ‹
            with open(file_path, 'rb') as f:
                raw = f.read(10000)  # è¯»å–å‰10KB

            # å°è¯•å¸¸è§ç¼–ç 
            for encoding in ['utf-8', 'gbk', 'gb2312', 'latin-1']:
                try:
                    raw.decode(encoding)
                    return encoding
                except:
                    continue

            return "unknown"
        except Exception as e:
            logger.error(f"Failed to detect encoding: {e}")
            return "unknown"

    def _parse_loading_guide(self, guide: str) -> Dict[str, Any]:
        """è§£æåŠ è½½æŒ‡å—"""
        return {
            "raw_guide": guide,
            "files": [],
            "schemas": {}
        }

    def _create_fix_prompt(self, code: str, error_msg: str, context: str) -> str:
        """åˆ›å»ºä¿®å¤prompt"""
        prompt = f"""Fix the following Python code:

## Error Message
{error_msg}

## Context
{context}

## Failed Code
```python
{code}
```

Provide the fixed code in JSON format with 'thought' and 'code' fields.
The 'code' field should contain the COMPLETE fixed script.
"""
        return prompt


# ==================== ä¾¿æ·å‡½æ•° ====================

async def get_enhanced_debug_context(
    dispatcher: AgentDispatcher,
    error_msg: str,
    chat_summary: str = ""
) -> str:
    """
    ä¸ºdebug agentæ„å»ºå¢å¼ºä¸Šä¸‹æ–‡

    è¿™ä¸ªå‡½æ•°å±•ç¤ºagentäº’ç›¸è°ƒç”¨çš„å®é™…åº”ç”¨ï¼š
    1. è°ƒç”¨DataExplorerè·å–æ–‡ä»¶ç»“æ„
    2. è°ƒç”¨DataExplorerè·å–schema
    3. å¦‚æœæœ‰æ•°æ®é”™è¯¯ï¼Œè°ƒç”¨DataExplorerç”ŸæˆåŠ è½½æŒ‡å—
    """
    context_parts = []

    # 1. è·å–æ–‡ä»¶æ ‘
    file_tree = dispatcher.get_file_tree_context()
    context_parts.append(file_tree)

    # 2. è·å–æ•°æ®schema
    schema_summary = dispatcher.get_data_schema_summary()
    context_parts.append(schema_summary)

    # 3. å¦‚æœæ˜¯æ•°æ®é”™è¯¯ï¼Œè°ƒç”¨DataExplorer agent
    data_error_keywords = [
        "FileNotFoundError", "No such file", "encoding",
        "column", "dtype", "KeyError"
    ]

    if any(kw in error_msg for kw in data_error_keywords):
        logger.info("ğŸ” æ•°æ®ç›¸å…³é—®é¢˜ - è°ƒç”¨ DataExplorer agent")

        # ä½¿ç”¨agentè°ƒç”¨æœºåˆ¶
        result = await dispatcher.call(
            target_agent=AgentType.DATA_EXPLORER,
            capability="analyze_schema",
            error_msg=error_msg,
            chat_summary=chat_summary
        )

        if result.get("success"):
            context_parts.append("\n## Data Loading Guide\n")
            context_parts.append(result.get("loading_guide", ""))

    return '\n'.join(context_parts)
