"""
DSLighting 2.0 æ ¸å¿ƒåè®®ç¤ºä¾‹ï¼šæ™ºèƒ½å·¥å…·é€‰æ‹© Agent

è¿™ä¸ªç¤ºä¾‹å±•ç¤ºå¦‚ä½•ä½¿ç”¨ DSLighting 2.0 çš„æ ¸å¿ƒåè®®ï¼ˆAction, Context, Toolï¼‰
å®ç°ä¸€ä¸ªèƒ½å¤Ÿæ ¹æ®ä»»åŠ¡çŠ¶æ€è‡ªåŠ¨é€‰æ‹©å·¥å…·çš„ Agentã€‚

åœºæ™¯ï¼šæ•°æ®åˆ†æä¸å»ºæ¨¡ä»»åŠ¡
æ•°æ®é›†ï¼šbike-sharing-demand
"""

import pandas as pd
import numpy as np
from typing import Dict, Any

# ============================================================================
# å¯¼å…¥ DSLighting 2.0 æ ¸å¿ƒåè®®
# ============================================================================

from dslighting import Action, Context, Tool

# ============================================================================
# 1. å®šä¹‰åŸºç¡€å·¥å…·
# ============================================================================

class DataTools:
    """æ•°æ®ç›¸å…³å·¥å…·é›†åˆ"""

    @staticmethod
    def load_data(file_path: str) -> pd.DataFrame:
        """åŠ è½½æ•°æ®"""
        print(f"ğŸ“‚ Loading data from {file_path}...")
        df = pd.read_csv(file_path)
        print(f"   âœ“ Loaded {len(df)} rows, {len(df.columns)} columns")
        return df

    @staticmethod
    def clean_data(df: pd.DataFrame) -> pd.DataFrame:
        """æ¸…æ´—æ•°æ®"""
        print("ğŸ§¹ Cleaning data...")

        # åˆ é™¤é‡å¤è¡Œ
        before = len(df)
        df = df.drop_duplicates()
        print(f"   âœ“ Removed {before - len(df)} duplicate rows")

        # å¤„ç†ç¼ºå¤±å€¼
        missing = df.isnull().sum().sum()
        if missing > 0:
            df = df.fillna(method='ffill').fillna(method='bfill')
            print(f"   âœ“ Filled {missing} missing values")

        return df

    @staticmethod
    def analyze_data(df: pd.DataFrame) -> Dict[str, Any]:
        """æ•°æ®åˆ†æ"""
        print("ğŸ“Š Analyzing data...")

        analysis = {
            'shape': df.shape,
            'columns': list(df.columns),
            'dtypes': {k: str(v) for k, v in df.dtypes.items()},
            'missing': df.isnull().sum().to_dict(),
            'numeric_summary': df.describe().to_dict()
        }

        print(f"   âœ“ Shape: {analysis['shape']}")
        print(f"   âœ“ Columns: {len(analysis['columns'])}")
        print(f"   âœ“ Missing values: {sum(analysis['missing'].values())}")

        return analysis


class ModelingTools:
    """å»ºæ¨¡ç›¸å…³å·¥å…·é›†åˆ"""

    @staticmethod
    def prepare_data(df: pd.DataFrame, target_column: str) -> Dict[str, Any]:
        """å‡†å¤‡å»ºæ¨¡æ•°æ®"""
        print(f"ğŸ¯ Preparing data for modeling (target: {target_column})...")

        # åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡
        X = df.drop(columns=[target_column])
        y = df[target_column]

        # è¯†åˆ«æ•°å€¼ç‰¹å¾
        numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()

        print(f"   âœ“ Features: {len(X.columns)}")
        print(f"   âœ“ Numeric features: {len(numeric_features)}")
        print(f"   âœ“ Samples: {len(X)}")

        return {
            'X': X,
            'y': y,
            'numeric_features': numeric_features
        }

    @staticmethod
    def train_model(X: pd.DataFrame, y: pd.Series,
                    model_type: str = "random_forest") -> Dict[str, Any]:
        """è®­ç»ƒæ¨¡å‹"""
        print(f"ğŸ¤– Training {model_type} model...")

        from sklearn.ensemble import RandomForestRegressor
        from sklearn.model_selection import train_test_split

        # ç®€å•çš„ç±»åˆ«ç‰¹å¾ç¼–ç 
        X_encoded = pd.get_dummies(X, drop_first=True)

        # åˆ†å‰²æ•°æ®
        X_train, X_test, y_train, y_test = train_test_split(
            X_encoded, y, test_size=0.2, random_state=42
        )

        # è®­ç»ƒæ¨¡å‹
        model = RandomForestRegressor(n_estimators=50, random_state=42)
        model.fit(X_train, y_train)

        # è¯„ä¼°
        train_score = model.score(X_train, y_train)
        test_score = model.score(X_test, y_test)

        print(f"   âœ“ Train score: {train_score:.4f}")
        print(f"   âœ“ Test score: {test_score:.4f}")

        return {
            'model': model,
            'model_type': model_type,
            'train_score': train_score,
            'test_score': test_score
        }

    @staticmethod
    def evaluate_model(model, X_test: pd.DataFrame, y_test: pd.Series) -> Dict[str, float]:
        """è¯„ä¼°æ¨¡å‹"""
        print("ğŸ“ˆ Evaluating model...")

        from sklearn.metrics import mean_squared_error, r2_score

        y_pred = model.predict(X_test)

        metrics = {
            'rmse': np.sqrt(mean_squared_error(y_test, y_pred)),
            'r2': r2_score(y_test, y_pred)
        }

        print(f"   âœ“ RMSE: {metrics['rmse']:.4f}")
        print(f"   âœ“ RÂ²: {metrics['r2']:.4f}")

        return metrics


# ============================================================================
# 2. å°†å‡½æ•°å°è£…æˆ Tool
# ============================================================================

load_data_tool = Tool(
    name="load_data",
    description="Load data from CSV file",
    fn=DataTools.load_data
)

clean_data_tool = Tool(
    name="clean_data",
    description="Clean data",
    fn=DataTools.clean_data
)

analyze_data_tool = Tool(
    name="analyze_data",
    description="Analyze data",
    fn=DataTools.analyze_data
)

prepare_data_tool = Tool(
    name="prepare_data",
    description="Prepare data for modeling",
    fn=ModelingTools.prepare_data
)

train_model_tool = Tool(
    name="train_model",
    description="Train ML model",
    fn=lambda X, y, model_type="random_forest": ModelingTools.train_model(X, y, model_type)
)

evaluate_model_tool = Tool(
    name="evaluate_model",
    description="Evaluate model",
    fn=lambda model, X_test, y_test: ModelingTools.evaluate_model(model, X_test, y_test)
)


# ============================================================================
# 3. å®ç°æ ¸å¿ƒ Agent - æ™ºèƒ½å·¥å…·é€‰æ‹©å™¨
# ============================================================================

class IntelligentToolSelector:
    """æ™ºèƒ½å·¥å…·é€‰æ‹© Agent"""

    def __init__(self, target_column: str = "count"):
        self.target_column = target_column
        self.step = 0
        self.history = []

        # å®šä¹‰å·¥ä½œæµç¨‹
        self.workflow_steps = [
            "load_data",
            "clean_data",
            "analyze_data",
            "prepare_data",
            "train_model",
            "evaluate_model"
        ]

    def plan(self, ctx: Context) -> Action:
        """è§„åˆ’æ–¹æ³•ï¼šæ ¹æ®å½“å‰çŠ¶æ€é€‰æ‹©ä¸‹ä¸€ä¸ªå·¥å…·"""

        current_step_name = self.workflow_steps[self.step]

        print(f"\n{'='*60}")
        print(f"ğŸ“ Step {self.step + 1}/{len(self.workflow_steps)}: {current_step_name}")
        print(f"{'='*60}")

        # æ ¹æ®æ­¥éª¤å†³å®šåŠ¨ä½œ
        if current_step_name == "load_data":
            return Action(
                tool="load_data",
                args={"file_path": ctx.data.get("file_path", "data.csv")}
            )

        elif current_step_name == "clean_data":
            return Action(
                tool="clean_data",
                args={"df": ctx.state.get("current_data")}
            )

        elif current_step_name == "analyze_data":
            return Action(
                tool="analyze_data",
                args={"df": ctx.state.get("current_data")}
            )

        elif current_step_name == "prepare_data":
            return Action(
                tool="prepare_data",
                args={
                    "df": ctx.state.get("current_data"),
                    "target_column": self.target_column
                }
            )

        elif current_step_name == "train_model":
            prepared = ctx.state.get("prepared_data", {})
            return Action(
                tool="train_model",
                args={
                    "X": prepared["X"],
                    "y": prepared["y"],
                    "model_type": "random_forest"
                }
            )

        elif current_step_name == "evaluate_model":
            prepared = ctx.state.get("prepared_data", {})
            model_info = ctx.state.get("model_info", {})

            from sklearn.model_selection import train_test_split
            X_encoded = pd.get_dummies(prepared["X"], drop_first=True)
            X_train, X_test, y_train, y_test = train_test_split(
                X_encoded, prepared["y"], test_size=0.2, random_state=42
            )

            return Action(
                tool="evaluate_model",
                args={
                    "model": model_info.get("model"),
                    "X_test": X_test,
                    "y_test": y_test
                }
            )

    def execute_action(self, ctx: Context, action: Action) -> Any:
        """æ‰§è¡ŒåŠ¨ä½œå¹¶æ›´æ–°çŠ¶æ€"""
        tool = ctx.get_tool(action.tool)
        result = tool(**action.args)

        self.step += 1

        # æ ¹æ®æ­¥éª¤ä¿å­˜å…³é”®ç»“æœ
        if action.tool == "load_data":
            ctx.state["current_data"] = result

        elif action.tool == "clean_data":
            ctx.state["current_data"] = result

        elif action.tool == "analyze_data":
            ctx.state["analysis"] = result

        elif action.tool == "prepare_data":
            ctx.state["prepared_data"] = result

        elif action.tool == "train_model":
            ctx.state["model_info"] = result

        elif action.tool == "evaluate_model":
            ctx.state["metrics"] = result

        self.history.append({
            'step': self.step,
            'tool': action.tool
        })

        return result

    def run(self, ctx: Context) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„æµç¨‹"""
        print("\nğŸš€ Starting Intelligent Tool Selector Agent")
        print(f"ğŸ¯ Target Column: {self.target_column}")

        while self.step < len(self.workflow_steps):
            action = self.plan(ctx)
            self.execute_action(ctx, action)

        print(f"\n{'='*60}")
        print("âœ… Workflow Complete!")
        print(f"{'='*60}")

        return ctx.state


# ============================================================================
# 4. ä½¿ç”¨ bike-sharing-demand æ•°æ®é›†æµ‹è¯•
# ============================================================================

def test_with_bike_sharing():
    """ä½¿ç”¨ bike-sharing-demand æ•°æ®é›†æµ‹è¯• Agent"""

    print("\n" + "="*80)
    print("DSLighting 2.0 Example: Intelligent Tool Selection Agent")
    print("Dataset: bike-sharing-demand (sample)")
    print("="*80 + "\n")

    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    import os

    data_path = "data/bike-sample/train.csv"

    if not os.path.exists(data_path):
        print("âš ï¸  Creating sample data...")

        np.random.seed(42)
        n_samples = 1000

        sample_data = pd.DataFrame({
            'datetime': pd.date_range('2023-01-01', periods=n_samples, freq='H'),
            'season': np.random.choice([1, 2, 3, 4], n_samples),
            'holiday': np.random.choice([0, 1], n_samples, p=[0.95, 0.05]),
            'workingday': np.random.choice([0, 1], n_samples, p=[0.3, 0.7]),
            'weather': np.random.choice([1, 2, 3], n_samples, p=[0.6, 0.3, 0.1]),
            'temp': np.random.normal(20, 10, n_samples),
            'humidity': np.random.normal(60, 20, n_samples),
            'windspeed': np.random.normal(15, 5, n_samples),
            'count': np.random.poisson(200, n_samples)
        })

        os.makedirs('data/bike-sample', exist_ok=True)
        sample_data.to_csv(data_path, index=False)

        print(f"âœ“ Sample data created: {data_path}")
        print(f"  Shape: {sample_data.shape}")
        print(f"  Columns: {', '.join(sample_data.columns)}\n")

    # åˆ›å»ºä¸Šä¸‹æ–‡
    tools = {
        'load_data': load_data_tool,
        'clean_data': clean_data_tool,
        'analyze_data': analyze_data_tool,
        'prepare_data': prepare_data_tool,
        'train_model': train_model_tool,
        'evaluate_model': evaluate_model_tool
    }

    ctx = Context(
        task="é¢„æµ‹å…±äº«å•è½¦ç§Ÿèµæ•°é‡",
        data={'file_path': data_path},
        tools=tools
    )

    # åˆ›å»º Agent
    agent = IntelligentToolSelector(target_column='count')

    # è¿è¡Œ Agent
    final_state = agent.run(ctx)

    # ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "="*60)
    print("ğŸ“Š Execution Summary")
    print("="*60)
    print(f"Total Steps: {len(agent.history)}")
    print(f"Tools Used: {', '.join([h['tool'] for h in agent.history])}")

    if 'metrics' in final_state:
        print(f"\nFinal Metrics:")
        for metric, value in final_state['metrics'].items():
            print(f"  â€¢ {metric}: {value:.4f}")

    print("\nâœ… Test completed successfully!")

    return final_state


# ============================================================================
# 5. é¢å¤–ç¤ºä¾‹ï¼šåŠ¨æ€å·¥å…·æ³¨å†Œ
# ============================================================================

def demo_dynamic_tool_registration():
    """æ¼”ç¤ºåŠ¨æ€æ³¨å†Œå·¥å…·"""

    print("\n" + "="*80)
    print("Demo: Dynamic Tool Registration")
    print("="*80 + "\n")

    # åˆ›å»ºä¸Šä¸‹æ–‡
    ctx = Context(
        task="æ¼”ç¤ºåŠ¨æ€å·¥å…·æ³¨å†Œ",
        data={"message": "Hello DSLighting 2.0!"},
        tools={}
    )

    # åŠ¨æ€åˆ›å»ºå¹¶æ³¨å†Œå·¥å…·
    custom_tool = Tool(
        name="custom_greeter",
        description="A custom greeting tool",
        fn=lambda msg: f"Hello! {msg}"
    )

    ctx.register_tool(custom_tool)

    # ä½¿ç”¨æ³¨å†Œçš„å·¥å…·
    tool = ctx.get_tool("custom_greeter")
    result = tool(ctx.data["message"])

    print(f"âœ“ Tool registered and used: {result}")
    print(f"âœ“ Available tools: {list(ctx.tools.keys())}\n")


# ============================================================================
# 6. ä¸»å‡½æ•°
# ============================================================================

if __name__ == "__main__":

    # è¿è¡Œä¸»æµ‹è¯•
    test_with_bike_sharing()

    # è¿è¡ŒåŠ¨æ€å·¥å…·æ³¨å†Œæ¼”ç¤º
    demo_dynamic_tool_registration()

    print("\n" + "="*80)
    print("ğŸ‰ All examples completed successfully!")
    print("="*80)
    print("\nğŸ’¡ Key Takeaways:")
    print("  1. Tool: ä»»ä½•åŠŸèƒ½éƒ½å¯ä»¥å°è£…æˆå·¥å…·")
    print("  2. Context: ç»Ÿä¸€çš„ä¸Šä¸‹æ–‡ï¼Œç»„è£…æ•°æ®å’Œå·¥å…·")
    print("  3. Agent: æ™ºèƒ½é€‰æ‹©å·¥å…·ï¼Œè‡ªåŠ¨åŒ–å·¥ä½œæµç¨‹")
    print("  4. å¯æ‰©å±•: è½»æ¾æ·»åŠ æ–°å·¥å…·å’Œæ–°åŠŸèƒ½\n")
