# MLE-Bench æ¯”èµ›ç›®å½•

æœ¬ç›®å½•åŒ…å«æ‰€æœ‰ MLE-Bench æ ¼å¼çš„æ¯”èµ›å®šä¹‰ã€‚

## ğŸ“š ç›®å½•ç»“æ„è¯´æ˜

MLE-Bench ä½¿ç”¨**ä¸¤ä¸ªç‹¬ç«‹çš„ç›®å½•**æ¥ç»„ç»‡æ¯”èµ›ï¼š

```
1ï¸âƒ£  æ¯”èµ›æ³¨å†Œç›®å½•ï¼ˆæœ¬ç›®å½•ï¼‰
   /path/to/data_science_agent_toolkit/mlebench/competitions/
   â””â”€â”€ <competition-id>/
       â”œâ”€â”€ config.yaml         âœ“ å¿…éœ€ - æ¯”èµ›é…ç½®
       â”œâ”€â”€ description.md      âœ“ å¿…éœ€ - æ¯”èµ›æè¿°
       â”œâ”€â”€ grade.py            âœ“ å¿…éœ€ - è¯„åˆ†å‡½æ•°
       â”œâ”€â”€ prepare.py          âœ“ å¿…éœ€ - æ•°æ®å‡†å¤‡å‡½æ•°
       â”œâ”€â”€ checksums.yaml      âœ“ å¿…éœ€ - æ•°æ®æ ¡éªŒ
       â””â”€â”€ leaderboard.csv     âœ“ å¿…éœ€ - æ’è¡Œæ¦œ

2ï¸âƒ£  æ•°æ®é›†ç›®å½•
   /path/to/mlebench-data/
   â””â”€â”€ <competition-id>/
       â”œâ”€â”€ prepare.py          # ä¾¿æ·å‡†å¤‡è„šæœ¬
       â”œâ”€â”€ raw/                # åŸå§‹æ•°æ®
       â””â”€â”€ prepared/           # å‡†å¤‡åçš„æ•°æ®
           â”œâ”€â”€ public/         # å‚èµ›è€…å¯è§
           â””â”€â”€ private/        # ç”¨äºè¯„åˆ†
```

è¯¦ç»†è¯´æ˜è¯·å‚è€ƒï¼š[/path/to/mle/competitions/README.md](../../mle/competitions/README.md)

## ğŸ“Š å·²æœ‰æ¯”èµ›ç»Ÿè®¡

### æŒ‰æ•°æ®æ¥æºåˆ†ç±»

#### 1. DSAgentBench æ•°æ®é›†ï¼ˆæ—¶é—´åºåˆ—ï¼‰

| æ¯”èµ› ID | åç§° | ä»»åŠ¡ç±»å‹ | è®­ç»ƒæ ·æœ¬ | æµ‹è¯•æ ·æœ¬ | è¯„ä¼°æŒ‡æ ‡ | éš¾åº¦ |
|---------|------|---------|----------|----------|----------|------|
| handwriting | Handwriting Time Series Classification | åˆ†ç±»ï¼ˆ26ç±»ï¼‰ | 150 | 850 | Accuracy | Easy |
| ethanol-concentration | Ethanol Concentration Classification | åˆ†ç±»ï¼ˆ4ç±»ï¼‰ | 261 | 263 | Accuracy | Easy |
| ili | ILI Time Series Forecasting | å¤šå˜é‡é¢„æµ‹ | 617 | 170 | MSE/MAE | Medium |

**ç‰¹ç‚¹**ï¼š
- æ•°æ®æ¨¡æ€ï¼šæ—¶é—´åºåˆ—
- æ ¼å¼ï¼š.ts æ–‡ä»¶ï¼ˆsktimeï¼‰æˆ– numpy arrays
- ç”¨é€”ï¼šå®Œæ•´çš„æœºå™¨å­¦ä¹  pipeline æ¯”èµ›

#### 2. DABench æ•°æ®é›†ï¼ˆæ•°æ®åˆ†æä»»åŠ¡ï¼‰

DABench ä»»åŠ¡æ˜¯ç®€å•çš„æ•°æ®åˆ†æä»»åŠ¡ï¼Œå¯¹åº” ML pipeline ä¸­çš„å•ä¸ªå­è¿‡ç¨‹ã€‚

**å·²è½¬æ¢çš„ç¤ºä¾‹**ï¼š

| æ¯”èµ› ID | ä»»åŠ¡ | æ¦‚å¿µ | éš¾åº¦ | æ•°æ®æ–‡ä»¶ |
|---------|------|------|------|----------|
| dabench-0-mean-fare | è®¡ç®—å¹³å‡ç¥¨ä»· | Summary Statistics | Easy | test_ave.csv |

**å¾…è½¬æ¢ä»»åŠ¡ç»Ÿè®¡**ï¼ˆå…±çº¦ 200+ ä¸ªä»»åŠ¡ï¼‰ï¼š

- **Summary Statistics**: å‡å€¼ã€ä¸­ä½æ•°ã€æ ‡å‡†å·®ç­‰
- **Feature Engineering**: ç‰¹å¾ç”Ÿæˆã€è½¬æ¢
- **Correlation Analysis**: ç›¸å…³æ€§åˆ†æ
- **Distribution Analysis**: åˆ†å¸ƒåˆ†æã€æ­£æ€æ€§æ£€éªŒ
- **Outlier Detection**: å¼‚å¸¸å€¼æ£€æµ‹
- **Machine Learning**: æ¨¡å‹è®­ç»ƒã€é¢„æµ‹ã€è¯„ä¼°
- **Data Preprocessing**: æ•°æ®æ¸…æ´—ã€ç¼ºå¤±å€¼å¤„ç†

**éš¾åº¦åˆ†å¸ƒ**ï¼š
- Easy: ~100 ä¸ªä»»åŠ¡
- Medium: ~70 ä¸ªä»»åŠ¡
- Hard: ~30 ä¸ªä»»åŠ¡

### æ€»ä½“ç»Ÿè®¡

```
æ€»æ¯”èµ›æ•°: 4 (3 DSAgentBench + 1 DABench)
æ•°æ®æ¨¡æ€: Time Series (3), Tabular (1)
ä»»åŠ¡ç±»å‹: åˆ†ç±» (2), é¢„æµ‹ (1), æ•°æ®åˆ†æ (1)
```

## ğŸ”„ æ‰¹é‡è½¬æ¢ DABench ä»»åŠ¡

### ä½¿ç”¨è½¬æ¢è„šæœ¬

ä½ç½®ï¼š`/path/to/convert_dabench_to_mlebench.py`

#### 1. åˆ—å‡ºæ‰€æœ‰å¯ç”¨ä»»åŠ¡

```bash
python convert_dabench_to_mlebench.py --list
```

ç¤ºä¾‹è¾“å‡ºï¼š
```
Available DABench tasks:
================================================================================
Task   0 [easy  ]: Calculate the mean fare paid by the passengers....
Task   5 [medium]: Generate a new feature called "FamilySize"...
Task   6 [medium]: Create a new column called "AgeGroup"...
...
================================================================================
Total: 200+ tasks
```

#### 2. è½¬æ¢å•ä¸ªæˆ–å¤šä¸ªä»»åŠ¡

```bash
# è½¬æ¢å•ä¸ªä»»åŠ¡
python convert_dabench_to_mlebench.py --task-ids 0

# è½¬æ¢å¤šä¸ªä»»åŠ¡
python convert_dabench_to_mlebench.py --task-ids 0 5 6 7

# Dry run (ä¸åˆ›å»ºæ–‡ä»¶ï¼Œä»…æµ‹è¯•)
python convert_dabench_to_mlebench.py --task-ids 0 --dry-run
```

#### 3. æ‰¹é‡è½¬æ¢æ‰€æœ‰ä»»åŠ¡

```bash
# è½¬æ¢æ‰€æœ‰ DABench ä»»åŠ¡ï¼ˆçº¦ 200+ ä¸ªï¼‰
python convert_dabench_to_mlebench.py --all

# Dry run æŸ¥çœ‹å°†åˆ›å»ºä»€ä¹ˆ
python convert_dabench_to_mlebench.py --all --dry-run
```

### è½¬æ¢åçš„ç»“æ„

æ¯ä¸ª DABench ä»»åŠ¡ä¼šåˆ›å»ºï¼š

**æ¯”èµ›æ³¨å†Œç›®å½•**ï¼š
```
mlebench/competitions/dabench-<id>-<keywords>/
â”œâ”€â”€ config.yaml
â”œâ”€â”€ description.md
â”œâ”€â”€ grade.py
â”œâ”€â”€ prepare.py
â”œâ”€â”€ leaderboard.csv
â””â”€â”€ checksums.yaml
```

**æ•°æ®é›†ç›®å½•**ï¼š
```
DSFlow/data/competitions/dabench-<id>-<keywords>/
â”œâ”€â”€ prepare.py
â”œâ”€â”€ raw/
â”‚   â””â”€â”€ <data_file>.csv
â””â”€â”€ prepared/
    â”œâ”€â”€ public/
    â”‚   â”œâ”€â”€ train.csv
    â”‚   â””â”€â”€ sample_submission.csv
    â””â”€â”€ private/
        â””â”€â”€ answer.csv
```

### å‡†å¤‡è½¬æ¢åçš„æ•°æ®

```bash
# è¿›å…¥æ•°æ®é›†ç›®å½•
cd /path/to/mlebench-data/dabench-<id>-<keywords>

# è¿è¡Œå‡†å¤‡è„šæœ¬
python prepare.py
```

## ğŸš€ è¿è¡Œæ¯”èµ›

### è¿è¡Œå•ä¸ªæ¯”èµ›

```bash
cd /path/to/data_science_agent_toolkit

conda run -n dstool python run_benchmark.py \
  --workflow aide \
  --benchmark mle \
  --mle-data-dir "/path/to/mlebench-data" \
  --llm-model openai/deepseek-ai/DeepSeek-V3.1-Terminus \
  --mle-competitions <competition-id>
```

### æ‰¹é‡è¿è¡Œå¤šä¸ªæ¯”èµ›

```bash
# è¿è¡Œå¤šä¸ª DABench ä»»åŠ¡
for task_id in 0 5 6; do
  python run_benchmark.py \
    --workflow aide \
    --benchmark mle \
    --mle-data-dir "/path/to/mlebench-data" \
    --llm-model openai/deepseek-ai/DeepSeek-V3.1-Terminus \
    --mle-competitions dabench-${task_id}-*
done
```

## ğŸ“ åˆ›å»ºæ–°æ¯”èµ›

### æ–¹å¼ 1: ä» DABench è½¬æ¢ï¼ˆæ¨èç”¨äºæ•°æ®åˆ†æä»»åŠ¡ï¼‰

ä½¿ç”¨ä¸Šè¿°è½¬æ¢è„šæœ¬è‡ªåŠ¨åˆ›å»ºã€‚

### æ–¹å¼ 2: æ‰‹åŠ¨åˆ›å»ºï¼ˆå®Œæ•´ ML ä»»åŠ¡ï¼‰

1. **åˆ›å»ºæ¯”èµ›å®šä¹‰**

```bash
cd /path/to/data_science_agent_toolkit
mkdir -p mlebench/competitions/<competition-id>
```

åˆ›å»º 6 ä¸ªå¿…éœ€æ–‡ä»¶ï¼š
- `config.yaml` - æ¯”èµ›é…ç½®
- `description.md` - æ¯”èµ›æè¿°
- `grade.py` - è¯„åˆ†å‡½æ•°
- `prepare.py` - æ•°æ®å‡†å¤‡å‡½æ•°
- `leaderboard.csv` - æ’è¡Œæ¦œ
- `checksums.yaml` - æ•°æ®æ ¡éªŒ

2. **å‡†å¤‡æ•°æ®**

```bash
cd /path/to/mlebench-data
mkdir -p <competition-id>/raw

# å¤åˆ¶åŸå§‹æ•°æ®
cp /path/to/data <competition-id>/raw/

# åˆ›å»ºä¾¿æ·å‡†å¤‡è„šæœ¬
cat > <competition-id>/prepare.py <<'EOF'
#!/usr/bin/env python3
import sys
from pathlib import Path
import importlib.util

prepare_file = Path('/path/to/data_science_agent_toolkit/mlebench/competitions/<competition-id>/prepare.py')
spec = importlib.util.spec_from_file_location("prepare_module", prepare_file)
prepare_module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(prepare_module)
prepare_fn = prepare_module.prepare

current_dir = Path(__file__).parent
raw_dir = current_dir / 'raw'
public_dir = current_dir / 'prepared' / 'public'
private_dir = current_dir / 'prepared' / 'private'

public_dir.mkdir(parents=True, exist_ok=True)
private_dir.mkdir(parents=True, exist_ok=True)

if __name__ == '__main__':
    print(f"Preparing <competition-id>...")
    prepare_fn(raw_dir, public_dir, private_dir)
    print("âœ“ Done!")
EOF

# è¿è¡Œå‡†å¤‡
python <competition-id>/prepare.py
```

è¯¦ç»†æŒ‡å—ï¼š[/path/to/mle/competitions/README.md](../../mle/competitions/README.md)

## âš™ï¸ æ•°æ®æ ¼å¼è¦æ±‚

### CSV æ ¼å¼æ˜¯å¼ºåˆ¶æ€§çš„

MLE-Bench æ¡†æ¶**åªæ¥å— CSV æ ¼å¼**çš„æäº¤å’Œç­”æ¡ˆæ–‡ä»¶ï¼š

```python
# æ¡†æ¶ä»£ç æ£€æŸ¥
submission_exists = (
    path_to_submission.is_file() and
    path_to_submission.suffix.lower() == ".csv"
)
```

### DABench ç‰¹æ®Šæ ¼å¼

DABench ä»»åŠ¡ä½¿ç”¨ç‰¹æ®Šçš„ç­”æ¡ˆæ ¼å¼ï¼š

```
@key1[value1] @key2[value2] ...
```

ç¤ºä¾‹ï¼š
```
@mean_fare[34.65]
@correlation_coefficient[0.21]
@mean_fare_child[31.09] @mean_fare_adult[35.17]
```

### å¤šç»´æ•°æ®å¤„ç†

å¯¹äºå¤šç»´è¾“å‡ºï¼ˆå¦‚æ—¶é—´åºåˆ—é¢„æµ‹ï¼‰ï¼Œéœ€è¦å±•å¹³ä¸º 2D CSVï¼š

```python
# 3D (N, 24, 7) -> 2D (N, 168)
predictions_flat = predictions.reshape(len(predictions), -1)
df = pd.DataFrame(predictions_flat, columns=[f'pred_{i}' for i in range(168)])
df.insert(0, 'id', range(len(predictions)))
df.to_csv('submission.csv', index=False)
```

## ğŸ” æµ‹è¯•æ¯”èµ›

### æµ‹è¯•è¯„åˆ†åŠŸèƒ½

åˆ›å»ºæµ‹è¯•è„šæœ¬ `test_grading.py`ï¼š

```python
import pandas as pd
import importlib.util
from pathlib import Path

# åŠ è½½ grade æ¨¡å—
grade_file = Path('mlebench/competitions/<competition-id>/grade.py')
spec = importlib.util.spec_from_file_location("grade_module", grade_file)
grade_module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(grade_module)
grade_fn = grade_module.grade

# åŠ è½½ç­”æ¡ˆ
answers = pd.read_csv('DSFlow/data/competitions/<competition-id>/prepared/private/answer.csv')

# æµ‹è¯•å®Œç¾æäº¤
perfect_submission = answers.copy()
score = grade_fn(perfect_submission, answers)
print(f"Perfect submission score: {score} (expected: 1.0)")

# æµ‹è¯•é”™è¯¯æäº¤
wrong_submission = pd.DataFrame({'id': [0], 'answer': ['@key[wrong_value]']})
score = grade_fn(wrong_submission, answers)
print(f"Wrong submission score: {score} (expected: 0.0)")
```

## ğŸ“– ç›¸å…³æ–‡æ¡£

### æ ¸å¿ƒæ–‡æ¡£

- **å®Œæ•´æŒ‡å—**: `/path/to/mle/competitions/README.md`
  - è¯¦ç»†çš„åˆ›å»ºæ­¥éª¤
  - ä¸¤ä¸ªç›®å½•çš„å…³ç³»
  - å¸¸è§é—®é¢˜è§£ç­”
  - ç¤ºä¾‹ä»£ç 

- **æ¯”èµ›ç´¢å¼•**: `/path/to/mle/competitions/INDEX.md`
  - æ‰€æœ‰æ¯”èµ›åˆ—è¡¨
  - å¯¹æ¯”è¡¨æ ¼

### ç‰¹å®šæ¯”èµ›æ–‡æ¡£

æ¯ä¸ªæ¯”èµ›å¯èƒ½åŒ…å«ï¼š
- `README.md` - æ¯”èµ›è¯´æ˜
- `FIXES.md` - ä¿®å¤è®°å½•ï¼ˆå¦‚æœ‰ï¼‰

ä¾‹å¦‚ï¼š
- `/path/to/mlebench-data/ili/README.md`
- `/path/to/mlebench-data/ili/FIXES.md`

## ğŸ¯ å¿«é€Ÿå¼€å§‹ç¤ºä¾‹

### ç¤ºä¾‹ 1: è½¬æ¢å¹¶è¿è¡Œä¸€ä¸ª DABench ä»»åŠ¡

```bash
# 1. è½¬æ¢ä»»åŠ¡
python convert_dabench_to_mlebench.py --task-ids 0

# 2. å‡†å¤‡æ•°æ®
cd /path/to/mlebench-data/dabench-0-mean-fare
python prepare.py

# 3. æµ‹è¯•è¯„åˆ†
python test_grading.py

# 4. è¿è¡Œæ¯”èµ›
cd /path/to/data_science_agent_toolkit
conda run -n dstool python run_benchmark.py \
  --workflow aide \
  --benchmark mle \
  --mle-data-dir "/path/to/mlebench-data" \
  --llm-model openai/deepseek-ai/DeepSeek-V3.1-Terminus \
  --mle-competitions dabench-0-mean-fare
```

### ç¤ºä¾‹ 2: æ‰¹é‡è½¬æ¢ Easy éš¾åº¦çš„ä»»åŠ¡

```bash
# åˆ—å‡ºæ‰€æœ‰ easy ä»»åŠ¡
python convert_dabench_to_mlebench.py --list | grep easy

# é€‰æ‹©ä¸€äº› easy ä»»åŠ¡è½¬æ¢
python convert_dabench_to_mlebench.py --task-ids 0 9 10 18 19 24 25 26

# æ‰¹é‡å‡†å¤‡æ•°æ®
for comp_id in dabench-*-*/; do
  cd "/path/to/mlebench-data/$comp_id"
  echo "Preparing $comp_id..."
  python prepare.py
done
```

## ğŸ› å¸¸è§é—®é¢˜

### Q1: è½¬æ¢è„šæœ¬æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶

**é”™è¯¯**: `âš  Warning: Data file not found: /path/to/DABench/da-dev-tables/xxx.csv`

**è§£å†³**: ç¡®ä¿ DABench æ•°æ®å·²ä¸‹è½½ï¼š
```bash
cd /path/to/DABench
python download_dabench.py
```

### Q2: å¯¼å…¥æ¨¡å—å¤±è´¥

**é”™è¯¯**: `ModuleNotFoundError: No module named 'mlebench.competitions.xxx'`

**è§£å†³**: ä½¿ç”¨ `importlib.util` ç›´æ¥ä»æ–‡ä»¶è·¯å¾„åŠ è½½ï¼š
```python
import importlib.util
spec = importlib.util.spec_from_file_location("module", "/path/to/file.py")
module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(module)
```

### Q3: æ¯”èµ› ID å‘½åå†²çª

å¦‚æœè½¬æ¢è„šæœ¬ç”Ÿæˆçš„æ¯”èµ› ID é‡å¤ï¼Œå¯ä»¥æ‰‹åŠ¨ä¿®æ”¹ï¼š
```bash
mv mlebench/competitions/dabench-X-keywords \
   mlebench/competitions/dabench-X-keywords-v2
```

å¹¶æ›´æ–° `config.yaml` ä¸­çš„ `id` å­—æ®µã€‚

## ğŸ“Š è´¡çŒ®ç»Ÿè®¡

```
DSAgentBench æ¯”èµ›: 3 ä¸ª
  - handwriting (2024-10-27)
  - ethanol-concentration (2024-10-27)
  - ili (2024-10-27, fixed CSV format)

DABench æ¯”èµ›: 1+ ä¸ª
  - dabench-0-mean-fare (2024-10-30, æµ‹è¯•æˆåŠŸ)
  - å¾…è½¬æ¢: ~200 ä¸ªä»»åŠ¡

æ€»è®¡: 4+ ä¸ªæ¯”èµ›
```

## ğŸ”— ç›¸å…³é“¾æ¥

- **MLE-Bench å®˜æ–¹ä»“åº“**: https://github.com/openai/mle-bench
- **DABench æ•°æ®é›†**: `/path/to/DABench`
- **DSAgentBench æ•°æ®é›†**: `/path/to/dsagentbench`

## ğŸ“ æ›´æ–°æ—¥å¿—

- **2024-10-30**: æ·»åŠ  DABench æ‰¹é‡è½¬æ¢è„šæœ¬å’Œæ–‡æ¡£
- **2024-10-30**: å®Œæˆ dabench-0-mean-fare æµ‹è¯•
- **2024-10-27**: åˆ›å»ºåˆå§‹ README
- **2024-10-27**: æ·»åŠ  DSAgentBench 3 ä¸ªæ¯”èµ›
- **2024-10-27**: ä¿®å¤ ili æ¯”èµ› CSV æ ¼å¼é—®é¢˜

## ğŸ“§ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·å‚è€ƒç›¸å…³æ–‡æ¡£æˆ–æŸ¥çœ‹ç¤ºä¾‹æ¯”èµ›çš„å®ç°ã€‚
