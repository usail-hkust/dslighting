LLM_MODEL=
LLM_TEMPERATURE=0.7
API_KEY=
API_BASE=

# Optional: per-model overrides (JSON object). If present, switching `--llm-model`
# will automatically use the matching api_key/api_base/provider/temperature.
#
# Example:
# LLM_MODEL_CONFIGS='{
#   "openai/deepseek-ai/DeepSeek-V3.1-Terminus": {
#     "api_key": ["sk-xxx", "sk-yyy"],
#     "api_base": "https://api.siliconflow.cn/v1",
#     "provider": "siliconflow",
#     "temperature": 1.0
#   },
#   "gpt-4o-mini": {
#     "api_key": "sk-openai-zzz",
#     "api_base": "https://api.openai.com/v1"
#   }
# }'
