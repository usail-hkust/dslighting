LLM_MODEL=
LLM_TEMPERATURE=0.7
API_KEY=
API_BASE=

# ============================================================================
# LLM Model Configuration (Optional)
# ============================================================================
#
# LLM_MODEL_CONFIGS allows you to configure multiple LLM models with their
# respective API keys, endpoints, and parameters. When you switch models using
# --llm-model flag, the system automatically uses the matching configuration.
#
# IMPORTANT: Two configuration formats (MUTUALLY EXCLUSIVE):
#
# Format 1: Use "provider" field (recommended for custom providers)
#   "model-name": {
#     "provider": "openai",  # or "anthropic", "siliconflow", etc.
#     "api_key": "sk-xxx",
#     "api_base": "https://api.example.com/v1"
#   }
#
# Format 2: Use "openai/" prefix (for OpenAI-compatible APIs)
#   "openai/model-name": {
#     "api_key": "sk-xxx",
#     "api_base": "https://api.example.com/v1"
#   }
#   NOTE: Do NOT use "provider" field with this format!
#
# ⚠️  WARNING: Never use BOTH "provider" AND "openai/" prefix together!
#            This will cause conflicts and errors.
#
# ============================================================================
# Supported Providers
# ============================================================================
#
# 1. OpenAI (Official)
#    Website: https://openai.com/
#    Models: gpt-4, gpt-4o, gpt-3.5-turbo, etc.
#
# 2. SiliconFlow (国内推荐 - 硅基流动)
#    Website: https://siliconflow.cn/
#    Models: deepseek-ai/DeepSeek-V3, Qwen/Qwen2.5-72B-Instruct, etc.
#    API Base: https://api.siliconflow.cn/v1
#
# 3. Zhipu AI (国内推荐 - 智谱AI)
#    Website: https://bigmodel.cn/
#    Models: glm-4, glm-4-plus, glm-4-air, etc.
#    API Base: https://open.bigmodel.cn/api/paas/v4
#
# ============================================================================
# Configuration Examples
# ============================================================================

LLM_MODEL_CONFIGS='{
  "gpt-4o": {
    "api_key": "sk-openai-placeholder-key",
    "api_base": "https://api.openai.com/v1",
    "temperature": 0.7
  },

  "glm-4.7": {
    "provider": "openai",
    "api_key": "your-zhipu-api-key-here",
    "api_base": "https://open.bigmodel.cn/api/paas/v4",
    "temperature": 1.0
  },

  "openai/deepseek-ai/DeepSeek-V3.1-Terminus": {
    "api_key": [
      "sk-siliconflow-key-1",
      "sk-siliconflow-key-2",
      "sk-siliconflow-key-3"
    ],
    "api_base": "https://api.siliconflow.cn/v1",
    "temperature": 1.0
  },

  "openai/moonshotai/Kimi-K2-Instruct-0905": {
    "api_key": [
      "sk-siliconflow-key-1",
      "sk-siliconflow-key-2"
    ],
    "api_base": "https://api.siliconflow.cn/v1",
    "temperature": 1.0
  },

  "openai/Qwen/Qwen2.5-72B-Instruct": {
    "api_key": "sk-siliconflow-key-here",
    "api_base": "https://api.siliconflow.cn/v1",
    "temperature": 0.8
  },

  "openai/custom-model-name": {
    "api_key": "your-custom-api-key",
    "api_base": "https://your-custom-endpoint.com/v1",
    "temperature": 1.0
  }
}'

# ============================================================================
# Notes
# ============================================================================
#
# 1. API Key Rotation:
#    You can provide multiple API keys as an array. The system will
#    automatically rotate through them for load balancing.
#
# 2. Temperature:
#    - Lower values (0.0-0.3): More focused and deterministic
#    - Medium values (0.4-0.7): Balanced creativity and consistency
#    - Higher values (0.8-1.5): More creative and random
#
# 3. Getting API Keys:
#    - OpenAI: https://platform.openai.com/api-keys
#    - SiliconFlow: https://siliconflow.cn/account/ak
#    - Zhipu AI: https://open.bigmodel.cn/usercenter/apikeys
#
# 4. Model Name Format:
#    - WITHOUT provider field: Use plain model name ("gpt-4o", "glm-4.7")
#    - WITH "openai/" prefix: Use full model path ("openai/deepseek-ai/DeepSeek-V3")
#    - Never combine both formats!
#
# ============================================================================

